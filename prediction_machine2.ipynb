{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction-machine2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-9ZJl9ZbT5MN",
        "sTFAmitRzH4Z"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brylimo/go-game-ranking-prediction-machine/blob/master/prediction_machine2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRJftud3L3Mi"
      },
      "source": [
        "## Load data and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1ekgDsG3f1t",
        "outputId": "8a3948b6-38a7-490e-8cb2-38b15149e3d2"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#load train data and label\n",
        "drive.mount('/content/drive')\n",
        "train_data_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/train_data.npy\" # Your train data file\n",
        "train_label_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/train_label.npy\" # Your train label file\n",
        "\n",
        "train_data = np.load(train_data_path, allow_pickle=True)\n",
        "train_label_rawdata = np.load(train_label_path, allow_pickle=True)  \n",
        "num_train_data = len(train_data)\n",
        "\n",
        "# character rating to integer rating\n",
        "rating = ['18k', '17k', '16k', '15k', '14k', '13k', '12k', '11k', '10k', \n",
        "          '9k', '8k', '7k', '6k', '5k', '4k', '3k', '2k', '1k',\n",
        "          '1d', '2d', '3d', '4d', '5d', '6d', '7d', '8d', '9d']\n",
        "\n",
        "train_label = np.zeros(num_train_data)\n",
        "for i in range(num_train_data):\n",
        "  train_label_temp = train_label_rawdata[i]\n",
        "  train_label_idx = rating.index(train_label_temp)\n",
        "  train_label[i] = train_label_idx\n",
        "\n",
        "# load test data and label\n",
        "test_data_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/test_data.npy\"\n",
        "test_data = np.load(test_data_path, allow_pickle=True)\n",
        "num_test_data = len(test_data)\n",
        "\n",
        "test_label_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/test_label2.npy\"\n",
        "test_label_rawdata = np.load(test_label_path, allow_pickle=True)\n",
        "\n",
        "test_label = np.zeros(num_test_data)\n",
        "for i in range(num_test_data):\n",
        "  test_label_temp = test_label_rawdata[i]\n",
        "  test_label_idx = rating.index(test_label_temp)\n",
        "  test_label[i] = test_label_idx\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f68_lwyZ_gAS"
      },
      "source": [
        "## Last train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi_CRigwB1Ed",
        "outputId": "dd32a741-5760-40d8-f278-ab86a8d89415"
      },
      "source": [
        "print(train_data.shape) # train_data is a list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2682,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FhEZ7YnAR-h",
        "outputId": "bfe239bf-a5db-4109-e2d7-cc4c83a90921"
      },
      "source": [
        "#check data shape\n",
        "print(len(train_data[0]))\n",
        "print(train_data[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "265\n",
            "(1, 19, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOw8FCFHAFn9",
        "outputId": "cd88534f-12aa-47da-feed-949ff5cfed73"
      },
      "source": [
        "print(len(train_data[1]))\n",
        "print(train_data[1][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "245\n",
            "(1, 19, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q4L1DyqB8m5",
        "outputId": "ed37f12d-456f-48c9-9b21-5ad09b13fbc8"
      },
      "source": [
        "print(len(train_data[2]))\n",
        "print(train_data[2][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "246\n",
            "(1, 19, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-EJKtjVBqGa",
        "outputId": "11eaf73e-1f52-4ce3-b537-6cb2830931cf"
      },
      "source": [
        "# Get last baduk data of first game (바둑경기 전체 수순에서 마지막 바둑판의 장면)\n",
        "teamp_last_data = train_data[0][-1]\n",
        "print(teamp_last_data) # 1 denotes a black stone. -1 denotes a white stone. 0 denotes an empty position."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0  0  0 -1  0  1  0  0  0  0  0  0 -1 -1 -1  1  1  0  1]\n",
            "  [ 0 -1 -1  0 -1  1 -1  1 -1 -1  0 -1  0 -1  0 -1  1  1  0]\n",
            "  [-1  0 -1 -1  1  0  1  1 -1  1 -1 -1 -1  0  0 -1  1 -1  1]\n",
            "  [ 0 -1  1  1  1  1  0  0 -1  1  1  1 -1 -1 -1  1  1 -1 -1]\n",
            "  [ 0  1  1  0  0  0  0  1 -1 -1  1  1  1  1  1  1 -1 -1  0]\n",
            "  [ 0  0  0  0  0  0  0  1  1 -1 -1  1  1 -1  1  1 -1 -1 -1]\n",
            "  [ 0  0  0  0  0  1  1 -1 -1  1 -1 -1 -1 -1  1  1  1 -1  0]\n",
            "  [ 0  0  0  0  0  1 -1  0 -1  0  1  1  0 -1 -1  1 -1  0 -1]\n",
            "  [ 0  0  1 -1 -1  1 -1  1 -1  1  0  1 -1  0  1 -1 -1  0  0]\n",
            "  [ 0  1  1  1  1 -1  0 -1  0 -1  1 -1  0 -1 -1 -1  0 -1 -1]\n",
            "  [ 0  0  1 -1 -1 -1 -1 -1 -1  0  1  0 -1  0  0  1 -1 -1  0]\n",
            "  [ 0  1  1  0  0  0 -1  0 -1  1  0  1  1  0  0  0  1 -1  0]\n",
            "  [ 0 -1  1 -1 -1 -1  1 -1  0  0  1  0  0  1  1  0  1 -1  0]\n",
            "  [ 0  0 -1  1  1  1  1  1  1  1  0  0 -1 -1  1  0  1  1 -1]\n",
            "  [-1 -1  0 -1  1  0  0  0 -1  1  0  0 -1  0 -1  1  1 -1  0]\n",
            "  [-1  1 -1 -1 -1 -1  0 -1  0 -1  1  0 -1  0 -1 -1 -1 -1 -1]\n",
            "  [ 1  0  1  1  1 -1  0  0  0  0 -1 -1 -1  0 -1  1  1 -1  1]\n",
            "  [ 0  1  0  0 -1  0  0  0  0  0  0 -1  1 -1  1  0  1  1  0]\n",
            "  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  1  1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xez7TS-XAS3h"
      },
      "source": [
        "# Get last baduk data of all game\n",
        "last_train_data = np.zeros( (num_train_data, 19,19) )\n",
        "\n",
        "for i in range(num_train_data):\n",
        "  temp_last_data = train_data[i][-1]\n",
        "  last_train_data[i, :, :] = temp_last_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYI_UzJdLlAb",
        "outputId": "15898618-7b81-4653-b1e3-9d54cb94f062"
      },
      "source": [
        "# Print last_train_data shape and contents\n",
        "print(last_train_data.shape) # shape\n",
        "print(last_train_data[50]) # content of 50-th games"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2682, 19, 19)\n",
            "[[-1.  0. -1. -1.  0. -1.  0. -1.  0. -1.  0. -1. -1. -1. -1.  1.  0.  1.\n",
            "   0.]\n",
            " [-1.  0. -1.  0. -1. -1.  0. -1. -1. -1.  0. -1.  0. -1. -1.  1.  1.  1.\n",
            "   1.]\n",
            " [ 0. -1.  0. -1. -1. -1. -1.  0. -1. -1. -1.  0.  0. -1. -1.  1.  0.  1.\n",
            "   1.]\n",
            " [-1.  0. -1. -1.  0.  0. -1. -1.  0. -1. -1.  0. -1. -1. -1.  1.  1.  1.\n",
            "   1.]\n",
            " [-1. -1.  0. -1. -1. -1.  0. -1. -1. -1.  0. -1.  0. -1. -1. -1. -1.  1.\n",
            "  -1.]\n",
            " [ 0.  0. -1.  0. -1.  0. -1. -1. -1. -1. -1.  0.  0. -1. -1.  0. -1. -1.\n",
            "  -1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1.  0. -1.  0. -1. -1. -1. -1.  0. -1.  1.  1.\n",
            "  -1.]\n",
            " [ 0. -1.  0. -1.  0. -1.  0. -1.  0. -1.  1.  1. -1.  0. -1.  1.  0.  1.\n",
            "   1.]\n",
            " [-1.  0. -1.  0. -1. -1. -1. -1. -1.  1.  0.  1. -1. -1.  1.  0.  1.  0.\n",
            "   1.]\n",
            " [ 0. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  0.  1.  0.  1.\n",
            "   1.]\n",
            " [-1. -1.  0. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
            "   0.]\n",
            " [ 0. -1.  0. -1.  1.  0.  1.  1.  0.  1.  1.  1.  0.  1.  0.  1.  0.  1.\n",
            "   1.]\n",
            " [-1. -1. -1.  1.  0.  1.  1.  1.  1. -1.  1. -1.  1.  0.  1.  0.  1.  1.\n",
            "   1.]\n",
            " [-1.  0. -1.  1.  1.  0.  1. -1. -1. -1. -1.  0. -1.  1.  1.  1.  0.  1.\n",
            "   1.]\n",
            " [-1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  0.\n",
            "   1.]\n",
            " [-1. -1. -1. -1.  1.  1. -1. -1.  0. -1. -1. -1. -1. -1. -1.  1.  0.  1.\n",
            "   0.]\n",
            " [-1. -1. -1.  0. -1. -1.  0. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  0.\n",
            "   1.]\n",
            " [ 0. -1. -1. -1. -1.  0.  0. -1.  0. -1. -1. -1. -1. -1.  1.  1.  0.  1.\n",
            "   0.]\n",
            " [-1.  0. -1. -1.  0. -1. -1.  0. -1.  0.  0. -1.  0. -1. -1.  1.  1.  0.\n",
            "   1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuvzlUTSMTR_",
        "outputId": "06b0ed24-04f8-44b6-88b5-f2bf850adc53"
      },
      "source": [
        "# Prepare data for training SVM\n",
        "last_train_data = np.reshape(last_train_data,(num_train_data, 19*19))\n",
        "print(last_train_data.shape) # check shape of last_train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2682, 361)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlS0FaJ41AWb"
      },
      "source": [
        "## Submit(final)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd7viFB10Jii",
        "outputId": "bfcca7ce-c140-4a89-e062-9f68b74ec3b0"
      },
      "source": [
        "# 전체 합치기(train_data 100%)\n",
        "new_train_data = np.concatenate((train_data, test_data), axis=0)\n",
        "new_train_label = np.concatenate((train_label, test_label), axis=0)\n",
        "\n",
        "num_new_train_data = len(new_train_data)\n",
        "print(new_train_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5372,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lLYhYNbyMO1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js9PwROs0w84"
      },
      "source": [
        "test2_data_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/Test2_data.npy\"\n",
        "test2_data = np.load(test2_data_path, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyM9ysKk1kXx",
        "outputId": "a61f4405-08ba-494c-a811-1190cd74c5b0"
      },
      "source": [
        "print(test2_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2700,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX9ICSW21n1h"
      },
      "source": [
        "num_test2_data = len(test2_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkPnn5Q_1riK"
      },
      "source": [
        "# train_data 100%\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "arr = np.zeros((num_test2_data, 27))\n",
        "\n",
        "total = 20\n",
        "for j in range(total):\n",
        "  real_train_label = new_train_label.copy()\n",
        "  real_train_label = pd.DataFrame(real_train_label)\n",
        "  real_train_data = pd.DataFrame(np.zeros((num_new_train_data, 19*19)))\n",
        "  k = 0\n",
        "  for i in range(num_new_train_data):\n",
        "    if k >= real_train_data.shape[0]:\n",
        "      break\n",
        "    length = len(new_train_data[k])\n",
        "    if length > j: \n",
        "      temp = pd.Series(new_train_data[k][j].reshape(19*19))\n",
        "      real_train_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      real_train_data.drop([k], axis=0, inplace=True)\n",
        "      real_train_label.drop([k], axis=0, inplace=True)\n",
        "    k+=1\n",
        "  \n",
        "  k = 0\n",
        "  real_test2_data = pd.DataFrame(np.zeros((num_test2_data, 19*19)))\n",
        "  chek = []\n",
        "  for i in range(num_test2_data):\n",
        "    if k >= real_test2_data.shape[0]:\n",
        "      break \n",
        "    length = len(test2_data[k])\n",
        "    if length > j:\n",
        "      temp = pd.Series(test2_data[k][j].reshape(19*19))\n",
        "      real_test2_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      chek.append(i)\n",
        "    k+=1\n",
        "\n",
        "  clf = LGBMClassifier(n_estimator=500, learning_rate=0.05)\n",
        "  clf.fit(real_train_data, real_train_label.values.ravel())\n",
        "  pred_proba = clf.predict_proba(real_test2_data)\n",
        "\n",
        "  count = np.full((num_test2_data, 1), total)\n",
        "  for i in chek:\n",
        "    pred_proba[i] = np.zeros((27, ))\n",
        "    count[i] = count[i] - 1\n",
        "  arr = arr + pred_proba\n",
        "\n",
        "arr = arr / count\n",
        "s_result = np.argmax(arr, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgKBcY-2QDG"
      },
      "source": [
        "s_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JEpY_tTHmDQ"
      },
      "source": [
        "submit = list_data = [str(rating[int(a)]).strip('\\n\\r') for a in s_result]\n",
        "submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsrpWIlHq68"
      },
      "source": [
        "!pip install pycryptodomex --no-binary :all:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNKy-LeUHuFw"
      },
      "source": [
        "!python -m Cryptodome.SelfTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32YL3pM5HyXQ"
      },
      "source": [
        "import json\n",
        "from base64 import b64encode\n",
        "from Cryptodome.Cipher import AES\n",
        "from Cryptodome.Util.Padding import pad\n",
        "\n",
        "def read_txt(fileName):\n",
        "    with open(fileName, 'rt') as f:\n",
        "        list_data = [a.strip('\\n\\r') for a in f.readlines()]\n",
        "    return list_data\n",
        "\n",
        "def write_json(fileName, data):\n",
        "    with open(fileName, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def load_key(key_path):\n",
        "    with open(key_path, \"rb\") as f:\n",
        "        key = f.read()\n",
        "    return key\n",
        "\n",
        "def encrypt_data(key_path, ans_list, encrypt_store_path='ans.json'):\n",
        "    key = load_key(key_path)\n",
        "    data = \" \".join([str(i) for i in ans_list])\n",
        "    encode_data = data.encode()\n",
        "    cipher = AES.new(key, AES.MODE_CBC)\n",
        "    ct_bytes = cipher.encrypt(pad(encode_data, AES.block_size))\n",
        "    iv = b64encode(cipher.iv).decode('utf-8')\n",
        "    ct = b64encode(ct_bytes).decode('utf-8')\n",
        "    write_json(encrypt_store_path, {'iv':iv, 'ciphertext':ct})\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # 1.이메일을 통해서 전달 받은 키 파일의 경로 입력\n",
        "    key_path = \"/content/drive/My Drive/team5.pem\"\n",
        "    # 2. 예측한 결과를 텍스트 파일로 저장했을 경우 리스트로 다시 불러오기\n",
        "    # 본인이 원하는 방식으로 리스트 형태로 예측 값을 불러오기만 하면 됨(순서를 지킬것)\n",
        "    # raw_ans_path = \"ans.txt\"\n",
        "    # ans = read_txt(raw_ans_path)\n",
        "    ans = submit\n",
        "    # 3. 암호화된 파일을 저장할 위치\n",
        "    encrypt_ans_path = \"/content/drive/My Drive/ans.json\"\n",
        "    # 4. 암호화!(pycrytodome 설치)\n",
        "    encrypt_data(key_path, ans, encrypt_ans_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTviAHo-H4qg"
      },
      "source": [
        "df = pd.DataFrame(arr, columns=rating)\n",
        "df.to_csv(\"/content/drive/My Drive/final.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ZJl9ZbT5MN"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "T5ojm7IdMTXf",
        "outputId": "1c6fbf68-c30e-4107-a51c-fac826110b3e"
      },
      "source": [
        "# 아래 new method(test_data 25%, train_data 75%)를 실행하게 된다면 먼저 실행해야함\n",
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "clf.fit(last_train_data, train_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dd47b31c3468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'last_train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEtVo84XMTb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "26db53bc-fe9c-4efc-de9f-e19debeedf46"
      },
      "source": [
        "# Get test data\n",
        "test_data_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/test_data.npy\"\n",
        "test_data = np.load(test_data_path, allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-69985c9752af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/test_data.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6dHGtCZMTg3"
      },
      "source": [
        "# Get last test data\n",
        "num_test_data = len(test_data)\n",
        "\n",
        "last_test_data = np.zeros( (num_test_data, 19, 19) )\n",
        "\n",
        "for i in range(num_test_data):\n",
        "  temp_last_data = test_data[i][-1]\n",
        "  last_test_data[i, :, :] = temp_last_data\n",
        "\n",
        "last_test_data = np.reshape(last_test_data, (num_test_data, 19*19))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYlAaHv3LlHn"
      },
      "source": [
        "# Predict test labels\n",
        "pred_test_label = clf.predict(last_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bthd7vH5acMG"
      },
      "source": [
        "# Get test labels (student does not have this ground-truth of test data)\n",
        "test_label_path = \"/content/drive/Shareddrives/기계학습5조/colab_data/baduk/test_label2.npy\"\n",
        "test_label_rawdata = np.load(test_label_path, allow_pickle=True)\n",
        "test_label = np.zeros(num_test_data)\n",
        "for i in range(num_test_data):\n",
        "  test_label_temp = test_label_rawdata[i]\n",
        "  test_label_idx = rating.index(test_label_temp)\n",
        "  test_label[i] = test_label_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9t7eKT_cbJO"
      },
      "source": [
        "# Accuracy on test data with SVM (baseline accuracy is 1/26=0.384)\n",
        "print('Accuracy on test data: ' + str(sum(pred_test_label==test_label)/len(test_label)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTFAmitRzH4Z"
      },
      "source": [
        "## new method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1ijeGKkKzSWD",
        "outputId": "834ea1fd-547f-4efd-daa6-b20c1b780b98"
      },
      "source": [
        "'''\n",
        "# test_data split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "n_iter=0\n",
        "train_idx = None\n",
        "test_idx = None\n",
        "\n",
        "for train_index, test_index in skf.split(last_test_data, test_label):\n",
        "  if n_iter == 0:\n",
        "    train_idx = train_index\n",
        "    test_idx = test_index\n",
        "  n_iter += 1\n",
        "\n",
        "print(train_idx.shape)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c4107b17de27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'last_test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9an472jWzWNf"
      },
      "source": [
        "'''\n",
        "# new_train_data + new_test_data\n",
        "new_train_data = np.concatenate((train_data, test_data[train_idx]), axis=0)\n",
        "new_train_label = np.concatenate((train_label, test_label[train_idx]), axis=0)\n",
        "new_test_data = test_data[test_idx]\n",
        "new_test_label = test_label[test_idx]\n",
        "\n",
        "num_new_train_data = len(new_train_data)\n",
        "num_new_test_data = len(new_test_data)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp1HfW8rzeU3"
      },
      "source": [
        "#print(new_train_label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjf5WW_Gzg6D"
      },
      "source": [
        "'''\n",
        "# test_data 25% + tain_data 75%일 때\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "arr = np.zeros((num_new_test_data, 27))\n",
        "\n",
        "# 첫번째 수순부터 20번째 수순까지 각 수순을 트레이닝하여 예측하고 예측 확률을 전부 합침\n",
        "# 합한 예측 확률이 가장 높은 기력을 최종적으로 선택\n",
        "total = 20\n",
        "for j in range(total):\n",
        "  real_train_label = new_train_label.copy()\n",
        "  real_train_label = pd.DataFrame(real_train_label)\n",
        "  real_train_data = pd.DataFrame(np.zeros((num_new_train_data, 19*19)))\n",
        "  k = 0\n",
        "  for i in range(num_new_train_data):\n",
        "    if k >= real_train_data.shape[0]:\n",
        "      break\n",
        "    length = len(new_train_data[k])\n",
        "    if length > j: \n",
        "      temp = pd.Series(new_train_data[k][j].reshape(19*19))\n",
        "      real_train_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      real_train_data.drop([k], axis=0, inplace=True)\n",
        "      real_train_label.drop([k], axis=0, inplace=True)\n",
        "    k+=1\n",
        "  \n",
        "  k = 0\n",
        "  real_test_data = pd.DataFrame(np.zeros((num_new_test_data, 19*19)))\n",
        "  chek = []\n",
        "  for i in range(num_new_test_data):\n",
        "    if k >= real_test_data.shape[0]:\n",
        "      break \n",
        "    length = len(new_test_data[k])\n",
        "    if length > j:\n",
        "      temp = pd.Series(new_test_data[k][j].reshape(19*19))\n",
        "      real_test_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      chek.append(i)\n",
        "    k+=1\n",
        "\n",
        "  # https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "  # ↑혹시 애매한 부분 있으면 참고하세요\n",
        "  if j == 0:   \n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=994, max_depth=2, min_child_weight=5, gamma=0, subsample=0.75, colsample_bytree=0.65, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 1:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=236, max_depth=9, min_child_weight=1, gamma=0, subsample=0.85, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 2:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=425, max_depth=5, min_child_weight=3, gamma=0.4, subsample=0.55, colsample_bytree=0.85, scale_pos_weight=1, random_state=156, reg_alpha=0.85)\n",
        "  elif j == 3:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=284, max_depth=6, min_child_weight=1, gamma=0.0, subsample=0.6, colsample_bytree=0.7, scale_pos_weight=1, random_state=156, reg_alpha=0.005)\n",
        "  elif j == 4:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=305, max_depth=7, min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.7, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 5:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=473, max_depth=4, min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 6:  \n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=585, max_depth=3, min_child_weight=1, gamma=0.3, subsample=0.8, colsample_bytree=0.75, scale_pos_weight=1, random_state=156, reg_alpha=0.01)\n",
        "  elif j == 7:  \n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=344, max_depth=5, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=1e-5)\n",
        "  elif j == 8:  \n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=654, max_depth=3, min_child_weight=1, gamma=0.2, subsample=0.6, colsample_bytree=0.7, scale_pos_weight=1, random_state=156, reg_alpha=1e-5)\n",
        "  elif j == 9: \n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=279, max_depth=9, min_child_weight=1, gamma=0.2, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=5e-05)\n",
        "  elif j == 15:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=280, max_depth=10, min_child_weight=2, gamma=0.4, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=0.01)\n",
        "  elif j == 16:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=297, max_depth=7, min_child_weight=3, gamma=0, subsample=0.85, colsample_bytree=0.85, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 17:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=303, max_depth=5, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.75, scale_pos_weight=1, random_state=156, reg_alpha=1)\n",
        "  elif j == 18:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=217, max_depth=7, min_child_weight=3, gamma=0.2, subsample=0.7, colsample_bytree=0.65, scale_pos_weight=1, random_state=156, reg_alpha=0)\n",
        "  elif j == 19:\n",
        "    clf = XGBClassifier(learning_rate =0.01, n_estimators=178, max_depth=9, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, random_state=156, reg_alpha=0.01)\n",
        "  else:\n",
        "    clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156)\n",
        "\n",
        "  clf.fit(real_train_data, real_train_label.values.ravel())\n",
        "  pred_proba = clf.predict_proba(real_test_data)\n",
        "\n",
        "  count = np.full((num_new_test_data, 1), total)\n",
        "  for i in chek:\n",
        "    pred_proba[i] = np.zeros((27, ))\n",
        "    count[i] = count[i] - 1\n",
        "  arr = arr + pred_proba\n",
        "\n",
        "arr = arr / count\n",
        "result = np.argmax(arr, axis=1)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YohVC43zrDb"
      },
      "source": [
        "'''\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(new_test_label, result)\n",
        "print('정확도: {}'.format(accuracy))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi9yhNN14zmy"
      },
      "source": [
        "# 바둑판 대칭"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX3wV7-q47El"
      },
      "source": [
        "## 가로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7mjGLyT46NT"
      },
      "source": [
        "import copy\n",
        "sup_train_data = copy.deepcopy(new_train_data)\n",
        "for i in range(num_new_train_data):\n",
        "  length = len(sup_train_data[i])\n",
        "  for j in range(length):\n",
        "      temp_sup_data = np.fliplr(sup_train_data[i][j][0])\n",
        "      sup_train_data[i][j][0][:,:] = temp_sup_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2psGpias_W1u"
      },
      "source": [
        "sup_train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2UiSQIk_W4W"
      },
      "source": [
        "new_train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j6j3by8_W7U"
      },
      "source": [
        "# 변형 합친 데이터\n",
        "sup_train_label = copy.deepcopy(new_train_label)\n",
        "new_train_data1 = np.concatenate((new_train_data, sup_train_data), axis=0)\n",
        "new_train_label1 = np.concatenate((new_train_label, sup_train_label), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2SVMd9C_W9y"
      },
      "source": [
        "num_new_train_data1 = len(new_train_data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxXoLV55_hcX"
      },
      "source": [
        "new_train_data1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFcYRq37_hf8"
      },
      "source": [
        "new_train_label1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTCtqoMk4-hl"
      },
      "source": [
        "##세로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtIRVGYS46Dw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "aedd6b3d-adf6-40f7-8dec-f9b724dd330c"
      },
      "source": [
        "import copy\n",
        "train_data_rv = copy.deepcopy(new_train_data)\n",
        "for i in range(num_new_train_data):\n",
        "  length = len(sup_train_data[i])\n",
        "  for j in range(length):\n",
        "      temp_sup_data = np.flipud(train_data_rv[i][j][0])\n",
        "      train_data_rv[i][j][0][:,:] = temp_sup_data\n",
        "\n",
        "#train_data_rv  : new_train_data를 세로 대칭한 데이터셋"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f5dfa36e9a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_data_rv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnew_train_data2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train_data_rv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_rv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDMNF5wT5EKb"
      },
      "source": [
        "##대각선"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw9BcFcR457R"
      },
      "source": [
        "\n",
        "#대각선 대칭\n",
        "\n",
        "#우상향 대각선\n",
        "new_train_data_di_r = new_train_data\n",
        "\n",
        "for i in range(num_new_train_data) :\n",
        "  for j in range(len(new_train_data[i])):\n",
        "    #print(i, j)\n",
        "    for x in range(19) :\n",
        "      for y in range(19) :\n",
        "        new_train_data_di_r[i][j][0][x][y]=new_train_data[i][j][0][18-y][18-x]\n",
        "\n",
        "\n",
        "#좌상향 대각선\n",
        "new_train_data_di_l = new_train_data\n",
        "\n",
        "for i in range(num_new_train_data) :\n",
        "  for j in range(len(new_train_data[i])):\n",
        "    #print(i, j)\n",
        "    for x in range(19) :\n",
        "      for y in range(19) :\n",
        "        new_train_data_di_l[i][j][0][x][y]=new_train_data[i][j][0][y][x]\n",
        "\n",
        "\n",
        "new_train_data3=np.concatenate((new_train_data,new_train_data_di_r), axis=0)\n",
        "new_train_label3=np.concatenate((new_train_label, new_train_label), axis=0)\n",
        "\n",
        "new_train_data3=np.concatenate((new_train_data3,new_train_data_di_l), axis=0)\n",
        "new_train_label3=np.concatenate((new_train_label3, new_train_label), axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJmzSn6CKbaW",
        "outputId": "170570a9-e39c-4e44-8154-1f0115d19a04"
      },
      "source": [
        "new_train_data3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16116,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUEDa1kPKeJ4",
        "outputId": "6ba52f05-b236-433f-f26c-6794319d5846"
      },
      "source": [
        "new_train_data3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16116,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "einJ3Ajn5Hia"
      },
      "source": [
        "##회전"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDqxmivZ5DXa"
      },
      "source": [
        "# 시계방향으로 90도 회전\n",
        "def rotate_CW_train_data(train_data):\n",
        "  length = len(train_data)\n",
        "  rotated = train_data.copy()\n",
        "\n",
        "  for i in range(length):\n",
        "    temp_game = train_data[i]\n",
        "    for j in range(len(temp_game)):\n",
        "      temp_play = temp_game[j][0]\n",
        "      rotated_play = np.array(list(zip(*temp_play[::-1]))) \n",
        "      rotated[i][j][0] = rotated_play\n",
        "  return rotated\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDSEZosJ9PaW"
      },
      "source": [
        "# train_data 100%, concat rotated data\n",
        "\n",
        "temp_new_train_data = np.concatenate((train_data, test_data), axis=0)\n",
        "temp_new_train_label = np.concatenate((train_label, test_label), axis=0)\n",
        "\n",
        "#회전한 데이터 붙이기 \n",
        "rotated_train_data = rotate_CW_train_data(temp_new_train_data) \n",
        "temp_new_train_data = np.concatenate((temp_new_train_data, rotated_train_data), axis=0) #1번 회전\n",
        "\n",
        "rotated_train_data = rotate_CW_train_data(rotated_train_data)\n",
        "temp_new_train_data = np.concatenate((temp_new_train_data, rotated_train_data), axis=0) #2번 회전\n",
        "\n",
        "rotated_train_data = rotate_CW_train_data(rotated_train_data)\n",
        "new_train_data4 = np.concatenate((temp_new_train_data, rotated_train_data), axis=0) #3번 회전\n",
        "\n",
        "temp_new_train_label = np.concatenate((temp_new_train_label, temp_new_train_label), axis=0)  #2배\n",
        "new_train_label4 = np.concatenate((temp_new_train_label, temp_new_train_label), axis=0)  #4배\n",
        "\n",
        "\n",
        "num_new_train_data4 = len(new_train_data4)\n",
        "\n",
        "print(new_train_data4.shape)\n",
        "print(new_train_label4.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZJVtuf9rv9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "arr = np.zeros((num_test2_data, 27))\n",
        "\n",
        "total = 22\n",
        "\n",
        "for j in range(total):\n",
        "  real_train_label = new_train_label.copy()\n",
        "  real_train_label = pd.DataFrame(real_train_label)\n",
        "  real_train_data = pd.DataFrame(np.zeros((num_new_train_data, 19*19)))\n",
        "  k = 0\n",
        "  for i in range(num_new_train_data):\n",
        "    if k >= real_train_data.shape[0]:\n",
        "      break\n",
        "    length = len(new_train_data[k])\n",
        "    if length > j: \n",
        "      temp = pd.Series(new_train_data[k][j].reshape(19*19))\n",
        "      real_train_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      real_train_data.drop([k], axis=0, inplace=True)\n",
        "      real_train_label.drop([k], axis=0, inplace=True)\n",
        "    k+=1\n",
        "  \n",
        "  k = 0\n",
        "  real_test2_data = pd.DataFrame(np.zeros((num_test2_data, 19*19)))\n",
        "  chek = []\n",
        "  for i in range(num_test2_data):\n",
        "    if k >= real_test2_data.shape[0]:\n",
        "      break \n",
        "    length = len(test2_data[k])\n",
        "    if length > j:\n",
        "      temp = pd.Series(test2_data[k][j].reshape(19*19))\n",
        "      real_test2_data.iloc[k, :] = temp\n",
        "    else:\n",
        "      chek.append(i)\n",
        "    k+=1\n",
        "\n",
        "  clf = LGBMClassifier(n_estimator=500)\n",
        "  clf.fit(real_train_data, real_train_label.values.ravel())\n",
        "  pred_proba = clf.predict_proba(real_test2_data)\n",
        "\n",
        "  count = np.full((num_test2_data, 1), total)\n",
        "  for i in chek:\n",
        "    pred_proba[i] = np.zeros((27, ))\n",
        "    count[i] = count[i] - 1\n",
        "  arr = arr + pred_proba\n",
        "\n",
        "arr = arr / count\n",
        "s_result = np.argmax(arr, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}